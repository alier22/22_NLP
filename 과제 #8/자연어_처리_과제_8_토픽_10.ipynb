{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4NSXnn1mbdz",
        "outputId": "9e1f9baf-8f34-4324-f39a-dd83f13a8a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 수 : 11314\n",
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data\n",
        "print('샘플의 수 :',len(documents))\n",
        "\n",
        "documents[1]\n",
        "\n",
        "print(dataset.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df = pd.DataFrame({'document':documents})\n",
        "# 특수 문자 제거\n",
        "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
        "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
        "# 전체 단어에 대한 소문자 변환\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ph8Aus_mmmh",
        "outputId": "4d62b33c-d031-4b5b-a76a-3f4e7fd63681"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-b4124dfb5e6a>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df['clean_doc'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "GHDvWBkjmmot",
        "outputId": "0aa13b08-3bfb-40a0-9fdb-10a0d6373de9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxIUon6pmmq-",
        "outputId": "caaff385-e097-4ecf-95cf-7bcca017c365"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK로부터 불용어를 받아온다.\n",
        "stop_words = stopwords.words('english')\n",
        "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화\n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "# 불용어를 제거합니다."
      ],
      "metadata": {
        "id": "SzpFSITHmmtW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_doc[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t6_GNcSmmvr",
        "outputId": "8fb2ce73-e022-4a8f-fb6d-5d1b8bcc5723"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 역토큰화 (토큰화 작업을 역으로 되돌림)\n",
        "detokenized_doc = []\n",
        "for i in range(len(news_df)):\n",
        "    t = ' '.join(tokenized_doc[i])\n",
        "    detokenized_doc.append(t)\n",
        "\n",
        "news_df['clean_doc'] = detokenized_doc"
      ],
      "metadata": {
        "id": "H6qRSDx9mmyF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_df['clean_doc'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "1CzxdqUjmm0d",
        "outputId": "67f6cdb7-9cc5-4207-e427-436abfeedbee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yeah expect people read actually accept hard atheism need little leap faith jimmy logic runs steam sorry pity sorry feelings denial faith need well pretend happily ever anyway maybe start newsgroup atheist hard bummin much forget flintstone chewables bake timmons'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000, # 상위 1,000개의 단어를 보존 \n",
        "max_df = 0.5, smooth_idf=True)\n",
        "\n",
        "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
        "\n",
        "# TF-IDF 행렬의 크기 확인\n",
        "print('TF-IDF 행렬의 크기 :',X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U_PaXRpmm39",
        "outputId": "d4d5f0f3-c7af-472b-8c07-a845a6f1823a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF 행렬의 크기 : (11314, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토픽 모델링"
      ],
      "metadata": {
        "id": "glnIVa7Pm0C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svd_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=100, random_state=122)\n",
        "svd_model.fit(X)\n",
        "len(svd_model.components_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDpfdCHGmzSD",
        "outputId": "94077707-6392-4808-9dd8-9e78c46333b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.\n",
        "\n",
        "def get_topics(components, feature_names, n=5):\n",
        "    for idx, topic in enumerate(components):\n",
        "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
        "get_topics(svd_model.components_,terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfdtRE4WmzUh",
        "outputId": "f5bd729c-2f81-4a5b-b758-27371f4b99b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: [('like', 0.21386), ('know', 0.20046), ('people', 0.19293), ('think', 0.17805), ('good', 0.15128)]\n",
            "Topic 2: [('thanks', 0.32888), ('windows', 0.29088), ('card', 0.18069), ('drive', 0.17455), ('mail', 0.15111)]\n",
            "Topic 3: [('game', 0.37064), ('team', 0.32443), ('year', 0.28154), ('games', 0.2537), ('season', 0.18419)]\n",
            "Topic 4: [('drive', 0.53324), ('scsi', 0.20165), ('hard', 0.15628), ('disk', 0.15578), ('card', 0.13994)]\n",
            "Topic 5: [('windows', 0.40399), ('file', 0.25436), ('window', 0.18044), ('files', 0.16078), ('program', 0.13894)]\n",
            "Topic 6: [('chip', 0.16114), ('government', 0.16009), ('mail', 0.15625), ('space', 0.1507), ('information', 0.13562)]\n",
            "Topic 7: [('like', 0.67086), ('bike', 0.14236), ('chip', 0.11169), ('know', 0.11139), ('sounds', 0.10371)]\n",
            "Topic 8: [('card', 0.46633), ('video', 0.22137), ('sale', 0.21266), ('monitor', 0.15463), ('offer', 0.14643)]\n",
            "Topic 9: [('know', 0.46047), ('card', 0.33605), ('chip', 0.17558), ('government', 0.1522), ('video', 0.14356)]\n",
            "Topic 10: [('good', 0.42756), ('know', 0.23039), ('time', 0.1882), ('bike', 0.11406), ('jesus', 0.09027)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA 실행 코드 "
      ],
      "metadata": {
        "id": "WIX_w-l-m7vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install genism"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeKVTpxUmzXQ",
        "outputId": "7b717b8c-68cb-4f7e-c621-75e79cd59c80"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement genism (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for genism\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora \n",
        "dictionary = corpora.Dictionary(tokenized_doc) \n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_doc] \n",
        "print(corpus[1]) # 수행된 결과에서 두번째 뉴스 출력. 첫번째 문서의 인덱스는 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icUCQ6PjmzZm",
        "outputId": "39a28dc5-65df-4432-a156-d32b81c36100"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(52, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "NUM_TOPICS = 10 # 20개의 토픽, k=20\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "topics = ldamodel.print_topics(num_words=4)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I3b0zE3mzcM",
        "outputId": "7b29606e-dd49-4d69-b466-4130c3706e50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.010*\"would\" + 0.008*\"people\" + 0.007*\"think\" + 0.005*\"know\"')\n",
            "(1, '0.013*\"space\" + 0.005*\"university\" + 0.005*\"nasa\" + 0.005*\"information\"')\n",
            "(2, '0.010*\"people\" + 0.009*\"would\" + 0.005*\"government\" + 0.004*\"think\"')\n",
            "(3, '0.008*\"game\" + 0.006*\"team\" + 0.006*\"play\" + 0.005*\"first\"')\n",
            "(4, '0.012*\"file\" + 0.007*\"program\" + 0.006*\"available\" + 0.006*\"files\"')\n",
            "(5, '0.009*\"bike\" + 0.006*\"ground\" + 0.005*\"wire\" + 0.004*\"good\"')\n",
            "(6, '0.011*\"year\" + 0.006*\"last\" + 0.006*\"league\" + 0.006*\"team\"')\n",
            "(7, '0.007*\"nrhj\" + 0.005*\"wwiz\" + 0.004*\"bxom\" + 0.004*\"gizw\"')\n",
            "(8, '0.021*\"armenian\" + 0.016*\"turkish\" + 0.015*\"armenians\" + 0.007*\"turks\"')\n",
            "(9, '0.009*\"would\" + 0.008*\"like\" + 0.007*\"know\" + 0.007*\"drive\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ldamodel.print_topics())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjLMABlFmze3",
        "outputId": "63bc937d-b0b3-4774-c39d-4fb2e231d8ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.010*\"would\" + 0.008*\"people\" + 0.007*\"think\" + 0.005*\"know\" + 0.005*\"like\" + 0.005*\"jesus\" + 0.005*\"believe\" + 0.005*\"even\" + 0.004*\"many\" + 0.004*\"time\"'), (1, '0.013*\"space\" + 0.005*\"university\" + 0.005*\"nasa\" + 0.005*\"information\" + 0.005*\"research\" + 0.004*\"data\" + 0.004*\"center\" + 0.004*\"available\" + 0.004*\"also\" + 0.003*\"national\"'), (2, '0.010*\"people\" + 0.009*\"would\" + 0.005*\"government\" + 0.004*\"think\" + 0.004*\"said\" + 0.004*\"know\" + 0.004*\"well\" + 0.003*\"time\" + 0.003*\"right\" + 0.003*\"like\"'), (3, '0.008*\"game\" + 0.006*\"team\" + 0.006*\"play\" + 0.005*\"first\" + 0.005*\"games\" + 0.005*\"like\" + 0.005*\"went\" + 0.005*\"back\" + 0.004*\"think\" + 0.004*\"would\"'), (4, '0.012*\"file\" + 0.007*\"program\" + 0.006*\"available\" + 0.006*\"files\" + 0.005*\"information\" + 0.005*\"output\" + 0.004*\"entry\" + 0.004*\"window\" + 0.004*\"version\" + 0.004*\"system\"'), (5, '0.009*\"bike\" + 0.006*\"ground\" + 0.005*\"wire\" + 0.004*\"good\" + 0.004*\"cover\" + 0.004*\"henrik\" + 0.004*\"ride\" + 0.004*\"pain\" + 0.004*\"miles\" + 0.003*\"engine\"'), (6, '0.011*\"year\" + 0.006*\"last\" + 0.006*\"league\" + 0.006*\"team\" + 0.006*\"runs\" + 0.004*\"players\" + 0.004*\"water\" + 0.004*\"good\" + 0.004*\"average\" + 0.004*\"better\"'), (7, '0.007*\"nrhj\" + 0.005*\"wwiz\" + 0.004*\"bxom\" + 0.004*\"gizw\" + 0.003*\"tbxn\" + 0.003*\"bhjn\" + 0.003*\"bxlt\" + 0.003*\"wmbxn\" + 0.003*\"nriz\" + 0.003*\"pnei\"'), (8, '0.021*\"armenian\" + 0.016*\"turkish\" + 0.015*\"armenians\" + 0.007*\"turks\" + 0.007*\"genocide\" + 0.007*\"turkey\" + 0.007*\"armenia\" + 0.004*\"muslim\" + 0.004*\"russian\" + 0.004*\"history\"'), (9, '0.009*\"would\" + 0.008*\"like\" + 0.007*\"know\" + 0.007*\"drive\" + 0.006*\"thanks\" + 0.006*\"also\" + 0.006*\"anyone\" + 0.006*\"problem\" + 0.005*\"system\" + 0.005*\"windows\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문서별 토픽 분포 보기 "
      ],
      "metadata": {
        "id": "jF0uhTIinAUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "    if i==5:\n",
        "        break\n",
        "    print(i,'번째 문서의 topic 비율은',topic_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tjb0FlqmzhJ",
        "outputId": "92685d15-97fc-4c26-8b26-1a5b6a8270d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 번째 문서의 topic 비율은 [(2, 0.9854825)]\n",
            "1 번째 문서의 topic 비율은 [(0, 0.91893375), (6, 0.06155213)]\n",
            "2 번째 문서의 topic 비율은 [(0, 0.16560353), (2, 0.6986081), (3, 0.036119662), (4, 0.08998995)]\n",
            "3 번째 문서의 topic 비율은 [(0, 0.20255503), (2, 0.1899682), (4, 0.3128432), (6, 0.110196546), (9, 0.17697272)]\n",
            "4 번째 문서의 topic 비율은 [(3, 0.96666044)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_topictable_per_doc(ldamodel, corpus):\n",
        "    topic_table = pd.DataFrame()\n",
        "\n",
        "    # 몇 번째 문서인지를 의미하는 문서 번호와 해당 문서의 토픽 비중을 한 줄씩 꺼내온다.\n",
        "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list            \n",
        "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
        "        # 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\n",
        "        # EX) 정렬 전 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (10번 토픽, 5%), (12번 토픽, 21.5%), \n",
        "        # Ex) 정렬 후 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (12번 토픽, 21.5%), (10번 토픽, 5%)\n",
        "        # 48 > 25 > 21 > 5 순으로 정렬이 된 것.\n",
        "\n",
        "        # 모든 문서에 대해서 각각 아래를 수행\n",
        "        for j, (topic_num, prop_topic) in enumerate(doc): #  몇 번 토픽인지와 비중을 나눠서 저장한다.\n",
        "            if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\n",
        "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\n",
        "                # 가장 비중이 높은 토픽과, 가장 비중이 높은 토픽의 비중과, 전체 토픽의 비중을 저장한다.\n",
        "            else:\n",
        "                break\n",
        "    return(topic_table)"
      ],
      "metadata": {
        "id": "pEcboI-Dmzki"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topictable = make_topictable_per_doc(ldamodel, corpus)\n",
        "topictable = topictable.reset_index() # 문서 번호을 의미하는 열(column)로 사용하기 위해서 인덱스 열을 하나 더 만든다.\n",
        "topictable.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n",
        "topictable[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "GH7cLGe-p_4L",
        "outputId": "7f414b14-f565-46b0-d14a-df8d46620bda"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   문서 번호  가장 비중이 높은 토픽  가장 높은 토픽의 비중  \\\n",
              "0      0           2.0        0.9855   \n",
              "1      1           0.0        0.9189   \n",
              "2      2           2.0        0.6986   \n",
              "3      3           4.0        0.3128   \n",
              "4      4           3.0        0.9667   \n",
              "5      5           0.0        0.7514   \n",
              "6      6           8.0        0.7088   \n",
              "7      7           2.0        0.5061   \n",
              "8      8           3.0        0.3683   \n",
              "9      9           9.0        0.6729   \n",
              "\n",
              "                                            각 토픽의 비중  \n",
              "0                                  [(2, 0.98548245)]  \n",
              "1                 [(0, 0.9189321), (6, 0.061554026)]  \n",
              "2  [(0, 0.16562147), (2, 0.69862056), (3, 0.03609...  \n",
              "3  [(0, 0.20266289), (2, 0.18990725), (4, 0.31283...  \n",
              "4                                  [(3, 0.96666044)]  \n",
              "5  [(0, 0.7513692), (6, 0.070813775), (8, 0.14864...  \n",
              "6  [(3, 0.010084361), (5, 0.013729511), (8, 0.708...  \n",
              "7  [(0, 0.31030843), (2, 0.5060919), (5, 0.156614...  \n",
              "8  [(0, 0.22279061), (1, 0.05294561), (2, 0.18968...  \n",
              "9  [(2, 0.13092947), (5, 0.1719134), (8, 0.016003...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-640d290a-1f5f-424c-8b91-78f5106eaa0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문서 번호</th>\n",
              "      <th>가장 비중이 높은 토픽</th>\n",
              "      <th>가장 높은 토픽의 비중</th>\n",
              "      <th>각 토픽의 비중</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.9855</td>\n",
              "      <td>[(2, 0.98548245)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9189</td>\n",
              "      <td>[(0, 0.9189321), (6, 0.061554026)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.6986</td>\n",
              "      <td>[(0, 0.16562147), (2, 0.69862056), (3, 0.03609...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.3128</td>\n",
              "      <td>[(0, 0.20266289), (2, 0.18990725), (4, 0.31283...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.9667</td>\n",
              "      <td>[(3, 0.96666044)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7514</td>\n",
              "      <td>[(0, 0.7513692), (6, 0.070813775), (8, 0.14864...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.7088</td>\n",
              "      <td>[(3, 0.010084361), (5, 0.013729511), (8, 0.708...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5061</td>\n",
              "      <td>[(0, 0.31030843), (2, 0.5060919), (5, 0.156614...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.3683</td>\n",
              "      <td>[(0, 0.22279061), (1, 0.05294561), (2, 0.18968...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.6729</td>\n",
              "      <td>[(2, 0.13092947), (5, 0.1719134), (8, 0.016003...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-640d290a-1f5f-424c-8b91-78f5106eaa0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-640d290a-1f5f-424c-8b91-78f5106eaa0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-640d290a-1f5f-424c-8b91-78f5106eaa0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rkCcs6ZSp_7b"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZY9_Czmp_-s"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpL8FzxBqAB9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sSDOWzVBqAFZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s5Ro9RRKqAIz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Nx5EXTbqAMv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jp5zn75gqAQS"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}