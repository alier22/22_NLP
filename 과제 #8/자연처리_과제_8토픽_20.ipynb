{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qQW3nvSgewWW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data\n",
        "print('샘플의 수 :',len(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAtCfPn2fK6E",
        "outputId": "3bae5d6a-33e2-4fc1-b27d-1cd0d9c9a07e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 수 : 11314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "LP9cy-NyfK8-",
        "outputId": "effbf1f3-b44a-4c71-c684-9534a8b94785"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9zt65qHfK_4",
        "outputId": "ac7018f5-36c4-4ea1-f3a5-9dc1d74768eb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df = pd.DataFrame({'document':documents})\n",
        "# 특수 문자 제거\n",
        "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
        "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
        "# 전체 단어에 대한 소문자 변환\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpkNhGeyfLDB",
        "outputId": "bb162598-d517-472c-a65e-0e86c03a9bc7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-b4124dfb5e6a>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df['clean_doc'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "BBNxjYSLfLG5",
        "outputId": "b4612a1b-9f3b-4a95-a81a-628d06df85cc"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzS1Fw8PgDAa",
        "outputId": "65dd6b26-414a-4d32-fb55-ddae2a04c3fa"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK로부터 불용어를 받아온다.\n",
        "stop_words = stopwords.words('english')\n",
        "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화\n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "# 불용어를 제거합니다."
      ],
      "metadata": {
        "id": "el-McsfKfLKQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_doc[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeZZwGS4fLNY",
        "outputId": "31a41246-d1b0-4baa-c3e0-9899b6339c4a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF 행렬 만들기"
      ],
      "metadata": {
        "id": "vR-7DYIsgdVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 역토큰화 (토큰화 작업을 역으로 되돌림)\n",
        "detokenized_doc = []\n",
        "for i in range(len(news_df)):\n",
        "    t = ' '.join(tokenized_doc[i])\n",
        "    detokenized_doc.append(t)\n",
        "\n",
        "news_df['clean_doc'] = detokenized_doc"
      ],
      "metadata": {
        "id": "pwDiKSrMga9e"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_df['clean_doc'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "UrLLr1NugbAZ",
        "outputId": "313109ab-abf5-4c50-e77b-f5401a2790d3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yeah expect people read actually accept hard atheism need little leap faith jimmy logic runs steam sorry pity sorry feelings denial faith need well pretend happily ever anyway maybe start newsgroup atheist hard bummin much forget flintstone chewables bake timmons'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000, # 상위 1,000개의 단어를 보존 \n",
        "max_df = 0.5, smooth_idf=True)\n",
        "\n",
        "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
        "\n",
        "# TF-IDF 행렬의 크기 확인\n",
        "print('TF-IDF 행렬의 크기 :',X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__JO313ggbDo",
        "outputId": "6f7ba90c-7b63-47cd-85b2-980da701ca4d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF 행렬의 크기 : (11314, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토픽 모델링"
      ],
      "metadata": {
        "id": "Olihei70gqg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svd_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=100, random_state=122)\n",
        "svd_model.fit(X)\n",
        "len(svd_model.components_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmSvdOu1gbGs",
        "outputId": "68e0e705-9afd-4e3d-ad60-5545c454f954"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(svd_model.components_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "7lm8uYXlgbJ7",
        "outputId": "eb8d0353-20e6-4673-e12c-58d65300b33f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-e4b0d6d34a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.\n",
        "\n",
        "def get_topics(components, feature_names, n=5):\n",
        "    for idx, topic in enumerate(components):\n",
        "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
        "get_topics(svd_model.components_,terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQebdWnOgbNS",
        "outputId": "e210e035-6f7a-4e16-d032-c567cd2458a1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: [('like', 0.21386), ('know', 0.20046), ('people', 0.19293), ('think', 0.17805), ('good', 0.15128)]\n",
            "Topic 2: [('thanks', 0.32888), ('windows', 0.29088), ('card', 0.18069), ('drive', 0.17455), ('mail', 0.15111)]\n",
            "Topic 3: [('game', 0.37064), ('team', 0.32443), ('year', 0.28154), ('games', 0.2537), ('season', 0.18419)]\n",
            "Topic 4: [('drive', 0.53324), ('scsi', 0.20165), ('hard', 0.15628), ('disk', 0.15578), ('card', 0.13994)]\n",
            "Topic 5: [('windows', 0.40399), ('file', 0.25436), ('window', 0.18044), ('files', 0.16078), ('program', 0.13894)]\n",
            "Topic 6: [('chip', 0.16114), ('government', 0.16009), ('mail', 0.15625), ('space', 0.1507), ('information', 0.13562)]\n",
            "Topic 7: [('like', 0.67086), ('bike', 0.14236), ('chip', 0.11169), ('know', 0.11139), ('sounds', 0.10371)]\n",
            "Topic 8: [('card', 0.46633), ('video', 0.22137), ('sale', 0.21266), ('monitor', 0.15463), ('offer', 0.14643)]\n",
            "Topic 9: [('know', 0.46047), ('card', 0.33605), ('chip', 0.17558), ('government', 0.1522), ('video', 0.14356)]\n",
            "Topic 10: [('good', 0.42756), ('know', 0.23039), ('time', 0.1882), ('bike', 0.11406), ('jesus', 0.09027)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA실행 코드 "
      ],
      "metadata": {
        "id": "HwCnr4NDj1Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install genism"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DppCO0mli61p",
        "outputId": "1ab3ffa5-da7b-4aab-9ea9-2aa815498017"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement genism (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for genism\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora \n",
        "dictionary = corpora.Dictionary(tokenized_doc) \n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_doc] \n",
        "print(corpus[1]) # 수행된 결과에서 두번째 뉴스 출력. 첫번째 문서의 인덱스는 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3x9eTpFi64b",
        "outputId": "623355a6-d3eb-41dc-a40e-eabc0bb6d79b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(52, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "NUM_TOPICS = 20 # 20개의 토픽, k=20\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "topics = ldamodel.print_topics(num_words=4)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9lo7mIMi67Z",
        "outputId": "3e2cc9bf-25a9-45d5-9ec7-3a7050884c1a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.010*\"available\" + 0.008*\"anonymous\" + 0.006*\"information\" + 0.006*\"contact\"')\n",
            "(1, '0.006*\"braves\" + 0.005*\"weaver\" + 0.005*\"cursor\" + 0.005*\"netcom\"')\n",
            "(2, '0.012*\"ground\" + 0.010*\"engine\" + 0.010*\"wire\" + 0.007*\"wiring\"')\n",
            "(3, '0.010*\"armenian\" + 0.009*\"israel\" + 0.009*\"jews\" + 0.009*\"armenians\"')\n",
            "(4, '0.012*\"like\" + 0.012*\"know\" + 0.010*\"would\" + 0.009*\"time\"')\n",
            "(5, '0.006*\"hawks\" + 0.004*\"adams\" + 0.003*\"apostles\" + 0.003*\"nords\"')\n",
            "(6, '0.036*\"jesus\" + 0.019*\"bible\" + 0.014*\"christ\" + 0.011*\"church\"')\n",
            "(7, '0.024*\"file\" + 0.018*\"output\" + 0.017*\"entry\" + 0.013*\"program\"')\n",
            "(8, '0.013*\"would\" + 0.011*\"people\" + 0.008*\"think\" + 0.006*\"many\"')\n",
            "(9, '0.017*\"char\" + 0.017*\"scsi\" + 0.007*\"byte\" + 0.005*\"column\"')\n",
            "(10, '0.026*\"space\" + 0.007*\"nasa\" + 0.006*\"data\" + 0.005*\"printf\"')\n",
            "(11, '0.011*\"drive\" + 0.009*\"would\" + 0.008*\"like\" + 0.008*\"card\"')\n",
            "(12, '0.020*\"mail\" + 0.016*\"list\" + 0.014*\"please\" + 0.014*\"send\"')\n",
            "(13, '0.013*\"year\" + 0.012*\"game\" + 0.008*\"last\" + 0.007*\"good\"')\n",
            "(14, '0.010*\"water\" + 0.009*\"insurance\" + 0.007*\"dept\" + 0.006*\"germany\"')\n",
            "(15, '0.012*\"period\" + 0.007*\"nrhj\" + 0.006*\"power\" + 0.006*\"scorer\"')\n",
            "(16, '0.011*\"encryption\" + 0.010*\"government\" + 0.009*\"chip\" + 0.009*\"keys\"')\n",
            "(17, '0.017*\"team\" + 0.015*\"hockey\" + 0.010*\"league\" + 0.008*\"games\"')\n",
            "(18, '0.013*\"windows\" + 0.009*\"file\" + 0.008*\"window\" + 0.008*\"version\"')\n",
            "(19, '0.007*\"people\" + 0.006*\"president\" + 0.006*\"government\" + 0.006*\"states\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ldamodel.print_topics())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MNm7u28i6-U",
        "outputId": "4472348b-459d-4491-8b60-8730e518dc74"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.010*\"available\" + 0.008*\"anonymous\" + 0.006*\"information\" + 0.006*\"contact\" + 0.006*\"center\" + 0.005*\"data\" + 0.005*\"computer\" + 0.005*\"university\" + 0.004*\"includes\" + 0.004*\"volume\"'), (1, '0.006*\"braves\" + 0.005*\"weaver\" + 0.005*\"cursor\" + 0.005*\"netcom\" + 0.005*\"colorado\" + 0.005*\"pitcher\" + 0.004*\"swap\" + 0.004*\"houston\" + 0.004*\"larson\" + 0.003*\"reds\"'), (2, '0.012*\"ground\" + 0.010*\"engine\" + 0.010*\"wire\" + 0.007*\"wiring\" + 0.007*\"picture\" + 0.006*\"neutral\" + 0.006*\"plastic\" + 0.004*\"sleeve\" + 0.004*\"electrical\" + 0.004*\"circuits\"'), (3, '0.010*\"armenian\" + 0.009*\"israel\" + 0.009*\"jews\" + 0.009*\"armenians\" + 0.009*\"people\" + 0.007*\"turkish\" + 0.006*\"said\" + 0.006*\"israeli\" + 0.005*\"turkey\" + 0.004*\"jewish\"'), (4, '0.012*\"like\" + 0.012*\"know\" + 0.010*\"would\" + 0.009*\"time\" + 0.007*\"back\" + 0.007*\"think\" + 0.007*\"said\" + 0.007*\"something\" + 0.007*\"going\" + 0.006*\"could\"'), (5, '0.006*\"hawks\" + 0.004*\"adams\" + 0.003*\"apostles\" + 0.003*\"nords\" + 0.003*\"smythe\" + 0.003*\"wales\" + 0.003*\"missing\" + 0.003*\"excellent\" + 0.003*\"blues\" + 0.003*\"echl\"'), (6, '0.036*\"jesus\" + 0.019*\"bible\" + 0.014*\"christ\" + 0.011*\"church\" + 0.010*\"christian\" + 0.008*\"word\" + 0.008*\"john\" + 0.008*\"matthew\" + 0.008*\"faith\" + 0.007*\"paul\"'), (7, '0.024*\"file\" + 0.018*\"output\" + 0.017*\"entry\" + 0.013*\"program\" + 0.008*\"line\" + 0.008*\"build\" + 0.007*\"section\" + 0.007*\"check\" + 0.007*\"open\" + 0.007*\"info\"'), (8, '0.013*\"would\" + 0.011*\"people\" + 0.008*\"think\" + 0.006*\"many\" + 0.006*\"like\" + 0.005*\"know\" + 0.005*\"even\" + 0.005*\"believe\" + 0.004*\"also\" + 0.004*\"time\"'), (9, '0.017*\"char\" + 0.017*\"scsi\" + 0.007*\"byte\" + 0.005*\"column\" + 0.005*\"bits\" + 0.005*\"icon\" + 0.005*\"terminals\" + 0.005*\"scope\" + 0.005*\"time\" + 0.004*\"pointer\"'), (10, '0.026*\"space\" + 0.007*\"nasa\" + 0.006*\"data\" + 0.005*\"printf\" + 0.005*\"also\" + 0.005*\"launch\" + 0.005*\"earth\" + 0.005*\"satellite\" + 0.004*\"program\" + 0.004*\"shuttle\"'), (11, '0.011*\"drive\" + 0.009*\"would\" + 0.008*\"like\" + 0.008*\"card\" + 0.007*\"system\" + 0.007*\"know\" + 0.006*\"disk\" + 0.006*\"used\" + 0.006*\"good\" + 0.006*\"also\"'), (12, '0.020*\"mail\" + 0.016*\"list\" + 0.014*\"please\" + 0.014*\"send\" + 0.010*\"email\" + 0.010*\"address\" + 0.009*\"information\" + 0.009*\"internet\" + 0.008*\"request\" + 0.007*\"posting\"'), (13, '0.013*\"year\" + 0.012*\"game\" + 0.008*\"last\" + 0.007*\"good\" + 0.006*\"team\" + 0.006*\"first\" + 0.006*\"games\" + 0.006*\"would\" + 0.006*\"season\" + 0.006*\"play\"'), (14, '0.010*\"water\" + 0.009*\"insurance\" + 0.007*\"dept\" + 0.006*\"germany\" + 0.005*\"sharks\" + 0.005*\"maine\" + 0.004*\"francis\" + 0.004*\"obfuscate\" + 0.004*\"emacs\" + 0.003*\"plant\"'), (15, '0.012*\"period\" + 0.007*\"nrhj\" + 0.006*\"power\" + 0.006*\"scorer\" + 0.005*\"play\" + 0.005*\"wwiz\" + 0.004*\"bxom\" + 0.004*\"gizw\" + 0.004*\"tbxn\" + 0.003*\"bhjn\"'), (16, '0.011*\"encryption\" + 0.010*\"government\" + 0.009*\"chip\" + 0.009*\"keys\" + 0.008*\"system\" + 0.008*\"security\" + 0.008*\"clipper\" + 0.007*\"privacy\" + 0.006*\"public\" + 0.006*\"would\"'), (17, '0.017*\"team\" + 0.015*\"hockey\" + 0.010*\"league\" + 0.008*\"games\" + 0.007*\"division\" + 0.007*\"chicago\" + 0.007*\"teams\" + 0.007*\"pittsburgh\" + 0.007*\"boston\" + 0.007*\"players\"'), (18, '0.013*\"windows\" + 0.009*\"file\" + 0.008*\"window\" + 0.008*\"version\" + 0.007*\"using\" + 0.007*\"files\" + 0.007*\"also\" + 0.007*\"program\" + 0.007*\"software\" + 0.007*\"available\"'), (19, '0.007*\"people\" + 0.006*\"president\" + 0.006*\"government\" + 0.006*\"states\" + 0.006*\"state\" + 0.005*\"would\" + 0.004*\"american\" + 0.004*\"right\" + 0.004*\"well\" + 0.004*\"control\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문서별 토픽 분포 보기 "
      ],
      "metadata": {
        "id": "pU2OvQmYjvER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "    if i==5:\n",
        "        break\n",
        "    print(i,'번째 문서의 topic 비율은',topic_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r0vkVXni7BJ",
        "outputId": "5b369b61-e57a-42fe-97ea-21958636591c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 번째 문서의 topic 비율은 [(3, 0.2154464), (8, 0.34465182), (19, 0.42619213)]\n",
            "1 번째 문서의 topic 비율은 [(3, 0.027881302), (4, 0.25536373), (8, 0.5322827), (9, 0.13961843), (14, 0.026561089)]\n",
            "2 번째 문서의 topic 비율은 [(1, 0.0491879), (3, 0.35602933), (4, 0.14973652), (8, 0.39269793), (11, 0.04025154)]\n",
            "3 번째 문서의 topic 비율은 [(1, 0.20776817), (4, 0.1799992), (11, 0.069908984), (12, 0.016938904), (16, 0.51419073)]\n",
            "4 번째 문서의 topic 비율은 [(4, 0.2801133), (17, 0.68655336)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_topictable_per_doc(ldamodel, corpus):\n",
        "    topic_table = pd.DataFrame()\n",
        "\n",
        "    # 몇 번째 문서인지를 의미하는 문서 번호와 해당 문서의 토픽 비중을 한 줄씩 꺼내온다.\n",
        "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list            \n",
        "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
        "        # 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\n",
        "        # EX) 정렬 전 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (10번 토픽, 5%), (12번 토픽, 21.5%), \n",
        "        # Ex) 정렬 후 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (12번 토픽, 21.5%), (10번 토픽, 5%)\n",
        "        # 48 > 25 > 21 > 5 순으로 정렬이 된 것.\n",
        "\n",
        "        # 모든 문서에 대해서 각각 아래를 수행\n",
        "        for j, (topic_num, prop_topic) in enumerate(doc): #  몇 번 토픽인지와 비중을 나눠서 저장한다.\n",
        "            if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\n",
        "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\n",
        "                # 가장 비중이 높은 토픽과, 가장 비중이 높은 토픽의 비중과, 전체 토픽의 비중을 저장한다.\n",
        "            else:\n",
        "                break\n",
        "    return(topic_table)"
      ],
      "metadata": {
        "id": "UcClcUoNi7Dv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topictable = make_topictable_per_doc(ldamodel, corpus)\n",
        "topictable = topictable.reset_index() # 문서 번호을 의미하는 열(column)로 사용하기 위해서 인덱스 열을 하나 더 만든다.\n",
        "topictable.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n",
        "topictable[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "O4vVNxSmi7HF",
        "outputId": "801cab8c-3f21-437d-c02b-4a4a49585d76"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   문서 번호  가장 비중이 높은 토픽  가장 높은 토픽의 비중  \\\n",
              "0      0          19.0        0.4262   \n",
              "1      1           8.0        0.5323   \n",
              "2      2           8.0        0.3927   \n",
              "3      3          16.0        0.5142   \n",
              "4      4          17.0        0.6864   \n",
              "5      5           8.0        0.3545   \n",
              "6      6           5.0        0.6461   \n",
              "7      7           8.0        0.3205   \n",
              "8      8          18.0        0.3074   \n",
              "9      9          11.0        0.4657   \n",
              "\n",
              "                                            각 토픽의 비중  \n",
              "0  [(3, 0.21545184), (8, 0.34465116), (19, 0.4261...  \n",
              "1  [(3, 0.027881343), (4, 0.25539014), (8, 0.5322...  \n",
              "2  [(1, 0.04918807), (3, 0.35603106), (4, 0.14976...  \n",
              "3  [(1, 0.20776743), (4, 0.18000905), (11, 0.0698...  \n",
              "4                 [(4, 0.2802799), (17, 0.68638676)]  \n",
              "5  [(4, 0.13292517), (5, 0.21952607), (6, 0.19587...  \n",
              "6  [(5, 0.64608824), (8, 0.04718778), (10, 0.0279...  \n",
              "7  [(3, 0.14909668), (4, 0.20083946), (6, 0.08753...  \n",
              "8  [(0, 0.034564245), (4, 0.18024746), (8, 0.2430...  \n",
              "9  [(4, 0.29005527), (8, 0.07505698), (9, 0.10296...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d0f63c4-8889-4638-b7af-2f420a2cd904\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문서 번호</th>\n",
              "      <th>가장 비중이 높은 토픽</th>\n",
              "      <th>가장 높은 토픽의 비중</th>\n",
              "      <th>각 토픽의 비중</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.4262</td>\n",
              "      <td>[(3, 0.21545184), (8, 0.34465116), (19, 0.4261...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.5323</td>\n",
              "      <td>[(3, 0.027881343), (4, 0.25539014), (8, 0.5322...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.3927</td>\n",
              "      <td>[(1, 0.04918807), (3, 0.35603106), (4, 0.14976...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.5142</td>\n",
              "      <td>[(1, 0.20776743), (4, 0.18000905), (11, 0.0698...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.6864</td>\n",
              "      <td>[(4, 0.2802799), (17, 0.68638676)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.3545</td>\n",
              "      <td>[(4, 0.13292517), (5, 0.21952607), (6, 0.19587...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.6461</td>\n",
              "      <td>[(5, 0.64608824), (8, 0.04718778), (10, 0.0279...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.3205</td>\n",
              "      <td>[(3, 0.14909668), (4, 0.20083946), (6, 0.08753...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.3074</td>\n",
              "      <td>[(0, 0.034564245), (4, 0.18024746), (8, 0.2430...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.4657</td>\n",
              "      <td>[(4, 0.29005527), (8, 0.07505698), (9, 0.10296...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d0f63c4-8889-4638-b7af-2f420a2cd904')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d0f63c4-8889-4638-b7af-2f420a2cd904 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d0f63c4-8889-4638-b7af-2f420a2cd904');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "teBweGeli7Km"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zxNjevZhfLRD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z2Y_5c_fkX9z"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}