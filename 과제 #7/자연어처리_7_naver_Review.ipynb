{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtHla9rEZlOX",
        "outputId": "f08f5576-bedb-4378-f0bb-34d28f075406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "\n",
        "import pandas as pd \n",
        "import sentencepiece as spm \n",
        "import urllib.request \n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from konlpy.tag import Okt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q612AROhbflD",
        "outputId": "0b5aa9ff-d11a-4c80-ae70-e4dd9afe44a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 331 kB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[K     |████████████████████████████████| 465 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\") \n",
        "\n",
        "naver_df = pd.read_table('ratings.txt')\n",
        "\n",
        "naver_df = naver_df.dropna(how = 'any') # Null 값이 존재하는 행 제거 \n",
        "\n",
        "# 결과를 naver_review.txt 파일에 저장\n",
        "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
        "\tf.write('\\n'.join(naver_df['document']))"
      ],
      "metadata": {
        "id": "Gq_329y9A7xE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "train_data = pd.read_table('naver_review.txt', header = None)\n",
        "#print(train_data)\n",
        "print(\"문장수  : \" ,len(train_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPjLsp-ZbgQQ",
        "outputId": "2cdcdfc6-cca1-4996-8dca-7a6f6952e64f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장수  :  198782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mml-Vt6out2",
        "outputId": "4748e140-2887-46ae-eace-c9d88eb994dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "193390"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# document 열의 중복 제거\n",
        "train_data.drop_duplicates(subset=[0], inplace=True)\n",
        "print('총 샘플의 수 :',len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O88dXUkKouwb",
        "outputId": "15a9eab7-bdd8-43b7-85b0-11d660cc67f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 수 : 193390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data[0] = train_data[0].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "# train_data[:5]"
      ],
      "metadata": {
        "id": "6YE1l6EgpIJR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0] = train_data[0].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n",
        "train_data[0].replace('', np.nan, inplace=True)\n",
        "print(train_data.isnull().sum())\n",
        "print(train_data.isnull())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA8w09GPpILt",
        "outputId": "c6fbb8f0-0b7b-4479-df23-3936986c016a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0\n",
            "dtype: int64\n",
            "            0\n",
            "0       False\n",
            "1       False\n",
            "2       False\n",
            "3       False\n",
            "4       False\n",
            "...       ...\n",
            "198777  False\n",
            "198778  False\n",
            "198779  False\n",
            "198780  False\n",
            "198781  False\n",
            "\n",
            "[193390 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.dropna(how = 'any')\n",
        "print(train_data)\n",
        "print(\"총 문장수 : \",len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgvOzVTzqVva",
        "outputId": "14ee76f1-07a2-4897-df24-74a74efdfd66"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                        0\n",
            "0                                     어릴때보고 지금다시봐도 재밌어요ㅋㅋ\n",
            "1       디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...\n",
            "2                    폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.\n",
            "3       와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...\n",
            "4                             안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.\n",
            "...                                                   ...\n",
            "198777                                     포켓 몬스터 짜가 ㅡㅡ;;\n",
            "198778                                              쓰.레.기\n",
            "198779                  완전 사이코영화. 마지막은 더욱더 이 영화의질을 떨어트린다.\n",
            "198780                왜난 재미없었지 ㅠㅠ 라따뚜이 보고나서 스머프 봐서 그런가 ㅋㅋ\n",
            "198781                                    포풍저그가나가신다영차영차영차\n",
            "\n",
            "[193390 rows x 1 columns]\n",
            "총 문장수 :  193390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in train_data[0]:\n",
        "  spword = i.split()\n",
        "\n",
        "  count += len(spword)\n",
        "print(\"총 단어수  : \" ,count)\n",
        "\n",
        "  #print(i)\n",
        "# w = train_data[0]\n",
        "# print(w)\n",
        "# lines = w[90001:90011].tolist()\n",
        "#print(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1HVwX6VvYI4",
        "outputId": "46837cc9-7db7-4a21-ee8d-90603e5e8ba8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 단어수  :  1509809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stopwords = ['의','가','이','을','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
      ],
      "metadata": {
        "id": "dy7nRcbDpIN0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train[:3])"
      ],
      "metadata": {
        "id": "bu1fvgCschvh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "okt = Okt()\n",
        "for sentence in tqdm(train_data[0]):\n",
        "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
        "    X_train.append(tokenized_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAodMJDnuHvq",
        "outputId": "a23c39bf-5703-4ca5-9ec3-b7a18cf21a55"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 193390/193390 [09:56<00:00, 324.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "Z9QqV_3jchx0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 3\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('고유단어수  :',total_cnt)\n",
        "#print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "#print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "#print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTQLRogxbgVG",
        "outputId": "efab0399-e029-4577-a8da-1e4372086406"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "고유단어수  : 56723\n"
          ]
        }
      ]
    }
  ]
}